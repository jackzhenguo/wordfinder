def getNGrams(wordlist, n):
    return [wordlist[i:i + n] for i in range(len(wordlist) - (n - 1))]

# Given a list of n-grams, return a dictionary of KWICs,
# indexed by keyword.


def nGramsToKWICDict(ngrams):
    keyindex = len(ngrams[0]) // 2

    kwicdict = {}

    for k in ngrams:
        if k[keyindex] not in kwicdict:
            kwicdict[k[keyindex]] = [k]
        else:
            kwicdict[k[keyindex]].append(k)
    return kwicdict


# Given a KWIC, return a string that is formatted for
# pretty printing.

def prettyPrintKWIC(kwic):
    n = len(kwic)
    keyindex = n // 2
    width = 10

    outstring = ' '.join(kwic[:keyindex]).rjust(width * keyindex)
    outstring += str(kwic[keyindex]).center(len(kwic[keyindex]) + 6)
    outstring += ' '.join(kwic[(keyindex + 1):])

    return outstring


def cut_to_sentence(text, keyword, keywordindex):
    """ Cuts the sentence around a keyword out of the text
    Arguments
    ----------
    text : str
        Text out of which the sentence should be extracted
    keyword : str
        Keyword in the sentence of the text
    keywordindex: int
        Index of the keyword in the text
    Returns
    -------
    Indices of of the sentence in the text and a string of the sentence
    """
    # Strings after wich a point does not end a sentence
    safe = ["Ms", "Mr", "Fr", "Hr", "Dipl", "B", "M", "Sc", "Dr", "Prof",
            "Mo", "Mon", "Di", "Tu", "Tue", "Tues", "Mi", "Wed", "Do", "Th",
            "Thu", "Thur", "Thurs", "Fr", "Fri", "Sa", "Sat", "So", "Sun",
            "0", "1", "2", "3", "4", "5", "6", "7", "8", "9",
            "str"]

    # Find beginning
    rfind_results = []
    end_ = keywordindex
    # Special Case "."
    while True:
        rfind_ = text.rfind(". ", 0, end_)
        if not rfind_ == -1:
            no_safe = False
            for i, s in enumerate(safe):
                if text[0:rfind_][::-1].find(s[::-1]) == 0:
                    end_ = rfind_ - len(s)
                    break
                if i == len(safe)-1:
                    no_safe = True
            if no_safe is True:
                break
        else:
            break
    rfind_results.append(rfind_)

    rfind_results.append(max([text.rfind(sentence_ending, 0, keywordindex)
                              for sentence_ending in ["! ", "? "]]))

    rfind_result = max(rfind_results)
    if rfind_result == -1:
        start = 0
    else:
        start = rfind_result + 2

    # Find ending
    find_results = []
    start_ = keywordindex+len(keyword)
    # Special Case "."
    while True:
        find_ = text.find(". ", start_)
        if not find_ == -1:
            no_safe = False
            for i, s in enumerate(safe):
                if text[0:find_][::-1].find(s[::-1]) == 0:
                    start_ = find_ + len(s)
                    break
                if i == len(safe)-1:
                    no_safe = True
            if no_safe is True:
                break
        else:
            break
    find_results.append(find_)

    find_results.extend([text.find(sentence_ending, keywordindex+len(keyword))
                         for sentence_ending in ["! ", "? "]])
    find_results_bigger_neg_1 = [i for i in find_results if i >= 0]
    if not find_results_bigger_neg_1:
        end = len(text)
    else:
        end = min(find_results_bigger_neg_1) + 1

    return list(range(start, end)), text[start:end]


def find_nth_occurrence(text, searchstr, nth=1, startindex=0):
    """
    Finds the index of the nth occurence of a searchstr in the text starting
    from the a given startindex.
    """
    start = text.find(searchstr, startindex)

    if start == -1:
        return len(text)-1

    for i in range(nth-1):
        find_index = text.find(searchstr, start+len(searchstr))
        if find_index == -1:
            return len(text)-1
        else:
            start = find_index

    return start


def rfind_nth_occurrence(text, searchstr, nth=1, endindex=None):
    """
    Finds the index of the nth occurence of a searchstr in the text going
    backwards from a given endindex.
    """
    if endindex is None:
        endindex = len(text)

    end = text.rfind(searchstr, 0, endindex)

    if end == -1:
        return 0

    for i in range(nth-1):
        rfind_index = text.rfind(searchstr, 0, end)
        if rfind_index == -1:
            return 0
        else:
            end = rfind_index

    return end


def keywords_in_context(text, keywords, max_words=5, sep="...", cut_sentences=True):
    """ Returns the relevant context around keywords in a larger text.
    Arguments
    ----------
    text : str
        Text which should be summerized around keywords.
    keywords : list of str
        Keywords whose context we want to extract out of the text.
    max_words : int
        Maximum number of words before und after a keyword if no sentence
        beginning or ending occurs and cut_sentences is set.
    sep : str
        String wich represents skipped portions of the text in the result.
    cut_sentences : bool
        Set if the context around a keyword is cut at the beginning or end of
        a sentence
    Returns
    -------
    Summarised text containing the keywords in context as string.
    """
    indices_lst = []
    for k in keywords:
        start = text.find(k)
        while not start == -1:
            indices_lst.append((k, start))
            start = text.find(k, start+len(k))

    result_indices = set()
    for index_tpl in indices_lst:
        keyword, index = index_tpl
        start = rfind_nth_occurrence(text, " ", nth=max_words+1, endindex=index)
        if not start == 0:
            start += 1 # +1 to Remove the first " "
        end = find_nth_occurrence(text, " ", nth=max_words+1, startindex=index+len(keyword))
        if end == len(text)-1:
            end += 1
        indices_of_text = set(range(start, end))
        if cut_sentences:
            sentence_indices, _ = cut_to_sentence(text, keyword, index)
            indices_of_text.intersection_update(set(sentence_indices))
        for i in indices_of_text:
            result_indices.add(i)

    result_indices = list(result_indices)
    result_indices.sort()

    result = ""
    i_before = -1
    for _i, i in enumerate(result_indices):
        if not (i-1) == i_before:
            result += " " + sep + " " + text[i]
            i_before = i
        else:
            result += text[i]
            i_before = i

        # If the last word is not the end of the text add the sperator.
        if _i == len(result_indices)-1:
            if not i == len(text)-1:
                result += " " + sep

    return result


def find_and_replace(text, find_str, replacement_str):
    """ Find and replace a find_str with a replacement_str in text. """
    start = text.find(find_str)
    offset = 0
    while start != -1:
        # update the index compatible to the whole text
        start = start + offset

        # replace (cut the original word out and insert the replacement)
        text = text[:start] + replacement_str + text[start+len(find_str):]
        prettyPrintKWIC(text)

        offset = start + len(replacement_str)
        start = text[offset:].find(find_str)

    return text


def prettyPrintKWIC(kwic):
    n = len(kwic)
    keyindex = n // 2
    width = 1

    outstring = ' '.join(kwic[:keyindex]).rjust(width*keyindex)
    outstring += str(kwic[keyindex]).center(len(kwic[keyindex])+6)
    outstring += ' '.join(kwic[(keyindex+1):])
    # print(outstring)
    return outstring


if __name__ == "__main__":
    """
    Text = Sentence which needs to be shrinked
    Keyword = Searched word
    """
    TEXTs = [
        'In 222 BC, the Romans besieged Acerrae, an Insubre fortification on the right bank of the River Adda between Cremona and Laus Pompeia (Lodi Vecchio).',
        'A spokesman for the bank said "We will be compensating customers who did not receive full services from Affinion, and providing our apology."',
        'One of the first fully functional direct banks in the United States was the Security First Network Bank (SFNB), which was launched in October 1995',
        'At the same time, internet-only banks or "virtual banks" appeared.',
        'Arriving at the Douro, Wellesley was unable to cross the river because Soult\'s army had either destroyed or moved all the boats to the northern bank.']
    KEYWORDS = ['bank']
    for TEXT in TEXTs:
        result_text = keywords_in_context(TEXT, KEYWORDS, max_words=3, sep="")
        # Highlight Keywords
        for k in KEYWORDS:
            result_text = find_and_replace(result_text, k, k)
            print(result_text)